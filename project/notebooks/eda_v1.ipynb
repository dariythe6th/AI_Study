{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, logging\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Optional, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(\"moodtune\")"
      ],
      "metadata": {
        "id": "2hwX2vdLRmtf"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_spotify_csv(path: str) -> str:\n",
        "    try:\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"CSV file not found: {path}\")\n",
        "\n",
        "        # Read CSV with error handling, trying common encodings\n",
        "        df = None\n",
        "        encodings = ['utf-8', 'latin1', 'cp1252'] # Add more encodings if needed\n",
        "        for encoding in encodings:\n",
        "            try:\n",
        "                df = pd.read_csv(path, encoding=encoding)\n",
        "                logger.info(f\"Successfully read CSV with encoding: {encoding}\")\n",
        "                break\n",
        "            except UnicodeDecodeError:\n",
        "                logger.warning(f\"Failed to read CSV with encoding {encoding}. Trying next...\")\n",
        "            except Exception as e:\n",
        "                raise ValueError(f\"Failed to read CSV file: {e}\")\n",
        "\n",
        "        if df is None:\n",
        "            raise ValueError(\"Could not read CSV file with any of the attempted encodings.\")\n",
        "\n",
        "        if df.empty:\n",
        "            raise ValueError(\"CSV file is empty\")\n",
        "\n",
        "        logger.info(f\"Original CSV shape: {df.shape}\")\n",
        "\n",
        "        # Clean column names\n",
        "        original_columns = list(df.columns)\n",
        "        df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]\n",
        "        logger.info(f\"Cleaned column names: {list(df.columns)}\")\n",
        "\n",
        "        # ========== DEFENSIVE COLUMN CHECKS ==========\n",
        "\n",
        "        # 1. Check for absolutely required columns\n",
        "        critical_columns = ['track_name', 'track_artist']\n",
        "        missing_critical = [col for col in critical_columns if col not in df.columns]\n",
        "        if missing_critical:\n",
        "            raise ValueError(\n",
        "                f\"Missing critical columns: {missing_critical}. File must contain at least track names and artists.\")\n",
        "\n",
        "        # 2. Check for expected columns and log warnings\n",
        "        expected_columns = {\n",
        "            'high_importance': ['track_name', 'track_artist', 'track_album_name', 'track_popularity'],\n",
        "            'medium_importance': ['playlist_genre', 'danceability', 'energy', 'valence', 'tempo'],\n",
        "            'low_importance': ['duration_ms', 'key', 'loudness', 'mode', 'speechiness', 'acousticness']\n",
        "        }\n",
        "\n",
        "        # Log missing columns by importance level\n",
        "        for importance_level, columns in expected_columns.items():\n",
        "            missing = [col for col in columns if col not in df.columns]\n",
        "            if missing:\n",
        "                logger.warning(f\"Missing {importance_level} columns: {missing}\")\n",
        "\n",
        "        # 3. Check for completely empty or useless columns\n",
        "        empty_columns = []\n",
        "        for col in df.columns:\n",
        "            if df[col].isna().all() or df[col].nunique() <= 1:\n",
        "                empty_columns.append(col)\n",
        "                logger.warning(f\"Column '{col}' is mostly empty or has no variation\")\n",
        "\n",
        "        # 4. Log available columns for debugging\n",
        "        available_high = [col for col in expected_columns['high_importance'] if col in df.columns]\n",
        "        available_medium = [col for col in expected_columns['medium_importance'] if col in df.columns]\n",
        "        available_low = [col for col in expected_columns['low_importance'] if col in df.columns]\n",
        "\n",
        "        logger.info(f\"Available high importance columns: {available_high}\")\n",
        "        logger.info(f\"Available medium importance columns: {available_medium}\")\n",
        "        logger.info(f\"Available low importance columns: {available_low}\")\n",
        "\n",
        "        # ========== COLUMN RENAMING WITH VALIDATION ==========\n",
        "        rename_map = {\n",
        "            'track_name': 'Track',\n",
        "            'track_artist': 'Artist',\n",
        "            'track_album_name': 'Album Name',\n",
        "            'track_popularity': 'Spotify Popularity',\n",
        "            'playlist_genre': 'Genre',\n",
        "        }\n",
        "\n",
        "        # Only rename columns that exist and log what's being renamed\n",
        "        existing_rename_map = {k: v for k, v in rename_map.items() if k in df.columns}\n",
        "        logger.info(f\"Renaming columns: {existing_rename_map}\")\n",
        "        df.rename(columns=existing_rename_map, inplace=True)\n",
        "\n",
        "        # ========== HANDLE MISSING COLUMNS WITH SMART DEFAULTS ==========\n",
        "\n",
        "        # Add Spotify Streams if missing (with realistic values based on popularity if available)\n",
        "        if 'Spotify Streams' not in df.columns:\n",
        "            if 'Spotify Popularity' in df.columns:\n",
        "                # Generate streams that correlate with popularity\n",
        "                base_streams = np.random.randint(10000, 1000000, len(df))\n",
        "                popularity_factor = df['Spotify Popularity'].fillna(50) / 100\n",
        "                df['Spotify Streams'] = (base_streams * (1 + popularity_factor * 4)).astype(int)\n",
        "            else:\n",
        "                df['Spotify Streams'] = np.random.randint(10000, 5000000, len(df))\n",
        "            logger.info(\"Added missing 'Spotify Streams' column with realistic values\")\n",
        "\n",
        "        # Add Release Date if missing\n",
        "        if 'Release Date' not in df.columns:\n",
        "            # Generate realistic release dates based on popularity (newer songs tend to be more popular)\n",
        "            if 'Spotify Popularity' in df.columns:\n",
        "                years = []\n",
        "                for pop in df['Spotify Popularity']:\n",
        "                    if pop > 80:  # Very popular - likely recent\n",
        "                        year = np.random.choice([2022, 2023, 2024])\n",
        "                    elif pop > 60:  # Moderately popular\n",
        "                        year = np.random.choice([2019, 2020, 2021, 2022])\n",
        "                    else:  # Less popular - could be older\n",
        "                        year = np.random.randint(2010, 2020)\n",
        "                    years.append(str(year))\n",
        "                df['Release Date'] = years\n",
        "            else:\n",
        "                df['Release Date'] = '2024'\n",
        "            logger.info(\"Added missing 'Release Date' column with context-aware values\")\n",
        "\n",
        "        # Add ISRC if missing\n",
        "        if 'ISRC' not in df.columns:\n",
        "            df['ISRC'] = [f\"custom_{i:06d}\" for i in range(len(df))]\n",
        "            logger.info(\"Added missing 'ISRC' column with generated IDs\")\n",
        "\n",
        "        # ========== DATA VALIDATION AND CLEANING ==========\n",
        "\n",
        "        # Ensure critical text columns exist and are properly formatted\n",
        "        critical_text_columns = ['Track', 'Artist']\n",
        "        for col in critical_text_columns:\n",
        "            if col in df.columns:\n",
        "                # Fill NaN and convert to string\n",
        "                df[col] = df[col].fillna('Unknown').astype(str)\n",
        "                # Remove extra whitespace\n",
        "                df[col] = df[col].str.strip()\n",
        "                # Check for empty strings after cleaning\n",
        "                empty_count = (df[col] == '').sum()\n",
        "                if empty_count > 0:\n",
        "                    logger.warning(f\"Column '{col}' has {empty_count} empty values after cleaning\")\n",
        "                    df[col] = df[col].replace('', 'Unknown')\n",
        "            else:\n",
        "                logger.error(f\"Critical column '{col}' missing after renaming!\")\n",
        "\n",
        "        # Ensure numeric columns are properly typed with validation\n",
        "        numeric_columns = ['Spotify Popularity', 'danceability', 'energy', 'valence', 'tempo']\n",
        "        for col in numeric_columns:\n",
        "            if col in df.columns:\n",
        "                original_dtype = df[col].dtype\n",
        "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "                # Check for conversion issues\n",
        "                na_count = df[col].isna().sum()\n",
        "                if na_count > 0:\n",
        "                    logger.warning(f\"Column '{col}' had {na_count} non-numeric values converted to NaN\")\n",
        "\n",
        "                # Fill NaN with sensible defaults based on column type\n",
        "                if col == 'Spotify Popularity':\n",
        "                    df[col] = df[col].fillna(30)  # Low popularity for unknown\n",
        "                elif col in ['danceability', 'energy', 'valence']:\n",
        "                    df[col] = df[col].fillna(0.5)  # Middle value for audio features\n",
        "                elif col == 'tempo':\n",
        "                    df[col] = df[col].fillna(120)  # Typical tempo\n",
        "\n",
        "                # Validate ranges\n",
        "                if col in ['danceability', 'energy', 'valence']:\n",
        "                    out_of_range = ((df[col] < 0) | (df[col] > 1)).sum()\n",
        "                    if out_of_range > 0:\n",
        "                        logger.warning(f\"Column '{col}' has {out_of_range} values outside [0,1] range - clipping\")\n",
        "                        df[col] = df[col].clip(0, 1)\n",
        "\n",
        "                logger.info(f\"Processed numeric column '{col}': {original_dtype} -> {df[col].dtype}\")\n",
        "\n",
        "        # Ensure other text columns are properly typed\n",
        "        optional_text_columns = ['Album Name', 'Genre']\n",
        "        for col in optional_text_columns:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].fillna('Unknown').astype(str).str.strip()\n",
        "                df[col] = df[col].replace('', 'Unknown')\n",
        "\n",
        "        # ========== FINAL DATA QUALITY CHECKS ==========\n",
        "\n",
        "        # Remove any completely empty rows\n",
        "        initial_count = len(df)\n",
        "        df = df.dropna(how='all')\n",
        "        if len(df) < initial_count:\n",
        "            logger.info(f\"Removed {initial_count - len(df)} completely empty rows\")\n",
        "\n",
        "        # Check for duplicate tracks\n",
        "        if 'Track' in df.columns and 'Artist' in df.columns:\n",
        "            duplicates = df.duplicated(subset=['Track', 'Artist']).sum()\n",
        "            if duplicates > 0:\n",
        "                logger.warning(f\"Found {duplicates} duplicate track-artist combinations\")\n",
        "\n",
        "        # Final dataset quality report\n",
        "        logger.info(f\"Final dataset shape: {df.shape}\")\n",
        "        logger.info(f\"Final columns: {list(df.columns)}\")\n",
        "\n",
        "        if df.empty:\n",
        "            raise ValueError(\"Dataset is empty after cleaning!\")\n",
        "\n",
        "        # Save cleaned data\n",
        "        cleaned_path = \"cleaned_spotify_data.csv\"\n",
        "        df.to_csv(cleaned_path, index=False)\n",
        "        logger.info(f\"✅ Cleaned CSV saved as {cleaned_path}\")\n",
        "\n",
        "        # Log sample of the cleaned data\n",
        "        logger.info(f\"Sample of cleaned data:\\n{df[['Track', 'Artist', 'Spotify Popularity']].head(3)}\")\n",
        "\n",
        "        return cleaned_path\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"CSV cleaning failed: {e}\")\n",
        "        logger.error(f\"Error type: {type(e).__name__}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "c70uuU5fRhKR"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_spotify_csv('high_popularity_spotify_data.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "vQsnkhYrUudw",
        "outputId": "f8fd8e6f-3970-496d-f270-a19d9d0fb15d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:moodtune:Missing low_importance columns: ['speechiness']\n",
            "WARNING:moodtune:Found 266 duplicate track-artist combinations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cleaned_spotify_data.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_basic_plots(df: pd.DataFrame, save_path: str = \"spotify_plots.png\") -> None:\n",
        "    \"\"\"\n",
        "    Создает 2-3 базовых графика для ключевых признаков Spotify данных.\n",
        "\n",
        "    Args:\n",
        "        df: Очищенный DataFrame с данными Spotify\n",
        "        save_path: Путь для сохранения графиков\n",
        "    \"\"\"\n",
        "    # Проверяем наличие необходимых колонок\n",
        "    available_cols = set(df.columns)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    fig.suptitle('Анализ Spotify данных', fontsize=14, fontweight='bold')\n",
        "\n",
        "    # 1. Гистограмма популярности треков (если есть)\n",
        "    if 'Spotify Popularity' in available_cols:\n",
        "        ax1 = axes[0]\n",
        "        df['Spotify Popularity'].hist(bins=30, ax=ax1, edgecolor='black', alpha=0.7)\n",
        "        ax1.set_xlabel('Популярность (0-100)')\n",
        "        ax1.set_ylabel('Количество треков')\n",
        "        ax1.set_title('Распределение популярности треков')\n",
        "        ax1.axvline(df['Spotify Popularity'].mean(), color='red', linestyle='--',\n",
        "                   label=f'Среднее: {df[\"Spotify Popularity\"].mean():.1f}')\n",
        "        ax1.legend()\n",
        "\n",
        "        # Добавляем статистику в виде текста\n",
        "        stats_text = f\"Медиана: {df['Spotify Popularity'].median():.1f}\\n\"\n",
        "        stats_text += f\"Std: {df['Spotify Popularity'].std():.1f}\"\n",
        "        ax1.text(0.05, 0.95, stats_text, transform=ax1.transAxes,\n",
        "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "    # 2. Boxplot для музыкальных характеристик\n",
        "    audio_features = ['danceability', 'energy', 'valence']\n",
        "    existing_features = [f for f in audio_features if f in available_cols]\n",
        "\n",
        "    if len(existing_features) >= 2:\n",
        "        ax2 = axes[1]\n",
        "        feature_data = [df[feat].dropna() for feat in existing_features]\n",
        "        boxplot = ax2.boxplot(feature_data, labels=existing_features, patch_artist=True)\n",
        "\n",
        "        # Раскрашиваем boxplot\n",
        "        colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
        "        for patch, color in zip(boxplot['boxes'], colors[:len(existing_features)]):\n",
        "            patch.set_facecolor(color)\n",
        "\n",
        "        ax2.set_ylabel('Значение (0-1)')\n",
        "        ax2.set_title('Распределение аудио-характеристик')\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    # 3. Scatter plot: Популярность vs Danceability (или другой параметр)\n",
        "    if all(col in available_cols for col in ['Spotify Popularity', 'danceability']):\n",
        "        ax3 = axes[2]\n",
        "\n",
        "        # Выбираем подвыборку для лучшей визуализации, если много точек\n",
        "        plot_df = df.copy()\n",
        "        if len(plot_df) > 1000:\n",
        "            plot_df = plot_df.sample(1000, random_state=42)\n",
        "\n",
        "        scatter = ax3.scatter(plot_df['danceability'], plot_df['Spotify Popularity'],\n",
        "                            c=plot_df['energy'] if 'energy' in available_cols else 'blue',\n",
        "                            alpha=0.6, s=50, cmap='viridis' if 'energy' in available_cols else None)\n",
        "\n",
        "        ax3.set_xlabel('Danceability (танцевальность)')\n",
        "        ax3.set_ylabel('Популярность')\n",
        "        ax3.set_title('Зависимость популярности от danceability')\n",
        "\n",
        "        if 'energy' in available_cols and scatter.get_cmap():\n",
        "            plt.colorbar(scatter, ax=ax3, label='Energy')\n",
        "\n",
        "        # Добавляем линию тренда\n",
        "        try:\n",
        "            z = np.polyfit(plot_df['danceability'], plot_df['Spotify Popularity'], 1)\n",
        "            p = np.poly1d(z)\n",
        "            ax3.plot(plot_df['danceability'], p(plot_df['danceability']), \"r--\", alpha=0.8)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    logger.info(f\"Графики сохранены в {save_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wedv1XmkXD4G"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_genre_analysis(df: pd.DataFrame, save_path: str = \"genre_analysis.png\") -> Optional[plt.Figure]:\n",
        "    \"\"\"\n",
        "    Анализ по жанрам, если данные доступны.\n",
        "    \"\"\"\n",
        "    if 'Genre' in df.columns and len(df['Genre'].unique()) > 1:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "        # 1. Количество треков по жанрам\n",
        "        genre_counts = df['Genre'].value_counts().head(10)\n",
        "        axes[0].barh(range(len(genre_counts)), genre_counts.values)\n",
        "        axes[0].set_yticks(range(len(genre_counts)))\n",
        "        axes[0].set_yticklabels(genre_counts.index)\n",
        "        axes[0].set_xlabel('Количество треков')\n",
        "        axes[0].set_title('Топ жанров по количеству треков')\n",
        "\n",
        "        # 2. Средняя популярность по жанрам\n",
        "        if 'Spotify Popularity' in df.columns:\n",
        "            genre_popularity = df.groupby('Genre')['Spotify Popularity'].mean().sort_values().tail(10)\n",
        "            axes[1].barh(range(len(genre_popularity)), genre_popularity.values)\n",
        "            axes[1].set_yticks(range(len(genre_popularity)))\n",
        "            axes[1].set_yticklabels(genre_popularity.index)\n",
        "            axes[1].set_xlabel('Средняя популярность')\n",
        "            axes[1].set_title('Средняя популярность по жанрам')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        return fig\n",
        "    return None"
      ],
      "metadata": {
        "id": "kn9BAUg5XJnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data_observations(df: pd.DataFrame) -> str:\n",
        "    \"\"\"\n",
        "    Генерирует 3-5 коротких текстовых наблюдений о данных.\n",
        "\n",
        "    Returns:\n",
        "        Строка с наблюдениями\n",
        "    \"\"\"\n",
        "    observations = [\"**НАБЛЮДЕНИЯ О ДАННЫХ SPOTIFY**\\n\"]\n",
        "\n",
        "    # 1. Общая статистика\n",
        "    observations.append(f\"1. **Объем данных**: {len(df)} треков, {len(df.columns)} характеристик\")\n",
        "\n",
        "    # 2. Популярность\n",
        "    if 'Spotify Popularity' in df.columns:\n",
        "        pop_stats = {\n",
        "            'Средняя': df['Spotify Popularity'].mean(),\n",
        "            'Медиана': df['Spotify Popularity'].median(),\n",
        "            'Максимальная': df['Spotify Popularity'].max(),\n",
        "            'Минимальная': df['Spotify Popularity'].min()\n",
        "        }\n",
        "        observations.append(f\"2. **Популярность треков**: Средняя {pop_stats['Средняя']:.1f}/100, \"\n",
        "                          f\"медиана {pop_stats['Медиана']:.1f}. \"\n",
        "                          f\"Самый популярный трек: {pop_stats['Максимальная']}/100, \"\n",
        "                          f\"самый непопулярный: {pop_stats['Минимальная']}/100\")\n",
        "\n",
        "    # 3. Аудио-характеристики\n",
        "    audio_cols = ['danceability', 'energy', 'valence', 'tempo']\n",
        "    available_audio = [col for col in audio_cols if col in df.columns]\n",
        "\n",
        "    if available_audio:\n",
        "        audio_stats = []\n",
        "        for col in available_audio:\n",
        "            if col in df.columns:\n",
        "                audio_stats.append(f\"{col}: {df[col].mean():.2f}\")\n",
        "\n",
        "        observations.append(f\"3. **Аудио-характеристики**: {', '.join(audio_stats)}\")\n",
        "\n",
        "        # Проверяем корреляцию между характеристиками\n",
        "        if len(available_audio) >= 2:\n",
        "            try:\n",
        "                corr_matrix = df[available_audio].corr()\n",
        "                # Находим самую сильную корреляцию (исключая диагональ)\n",
        "                strongest_corr = 0\n",
        "                strongest_pair = None\n",
        "                for i in range(len(available_audio)):\n",
        "                    for j in range(i+1, len(available_audio)):\n",
        "                        corr_val = abs(corr_matrix.iloc[i, j])\n",
        "                        if corr_val > strongest_corr:\n",
        "                            strongest_corr = corr_val\n",
        "                            strongest_pair = (available_audio[i], available_audio[j],\n",
        "                                           corr_matrix.iloc[i, j])\n",
        "\n",
        "                if strongest_pair and abs(strongest_pair[2]) > 0.3:\n",
        "                    corr_dir = \"положительной\" if strongest_pair[2] > 0 else \"отрицательной\"\n",
        "                    observations.append(f\"4. **Корреляции**: Наибольшая {corr_dir} связь между \"\n",
        "                                      f\"'{strongest_pair[0]}' и '{strongest_pair[1]}' \"\n",
        "                                      f\"(r = {strongest_pair[2]:.2f})\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    # 4. Жанры\n",
        "    if 'Genre' in df.columns and len(df['Genre'].unique()) > 1:\n",
        "        top_genres = df['Genre'].value_counts().head(3)\n",
        "        observations.append(f\"5. **Распределение по жанрам**: {', '.join([f'{g} ({c})' for g, c in top_genres.items()])}\")\n",
        "\n",
        "    # 5. Длительность треков\n",
        "    if 'duration_ms' in df.columns:\n",
        "        avg_duration = df['duration_ms'].mean() / 60000  # в минуты\n",
        "        observations.append(f\"6. **Длительность треков**: Средняя {avg_duration:.2f} минут\")\n",
        "\n",
        "    # 6. Пропущенные значения\n",
        "    missing_percent = (df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100\n",
        "    if missing_percent > 0:\n",
        "        observations.append(f\"7. **Качество данных**: {missing_percent:.1f}% пропущенных значений\")\n",
        "\n",
        "    # Если наблюдений меньше 5, добавляем дополнительные\n",
        "    if len(observations) < 5:\n",
        "        observations.append(f\"8. **Уникальных артистов**: {df['Artist'].nunique() if 'Artist' in df.columns else 'N/A'}\")\n",
        "        observations.append(f\"9. **Уникальных треков**: {df['Track'].nunique() if 'Track' in df.columns else 'N/A'}\")\n",
        "\n",
        "    return \"\\n\".join(observations[:6])  # Возвращаем первые 6 наблюдений\n"
      ],
      "metadata": {
        "id": "WQBrBVGySyWo"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def analyze_spotify_data(df: pd.DataFrame) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Полный анализ данных: графики + наблюдения.\n",
        "\n",
        "    Returns:\n",
        "        Кортеж (путь_к_графикам, текстовые_наблюдения)\n",
        "    \"\"\"\n",
        "    logger.info(\"Начинаем анализ данных...\")\n",
        "\n",
        "    # Создаем графики\n",
        "    try:\n",
        "        create_basic_plots(df, \"spotify_basic_analysis.png\")\n",
        "\n",
        "        # Дополнительный анализ по жанрам\n",
        "        if 'Genre' in df.columns:\n",
        "            create_genre_analysis(df, \"spotify_genre_analysis.png\")\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Не удалось создать графики: {e}\")\n",
        "\n",
        "    # Генерируем наблюдения\n",
        "    observations = generate_data_observations(df)\n",
        "\n",
        "    # Выводим наблюдения\n",
        "    logger.info(\"\\n\" + \"=\"*50)\n",
        "    logger.info(observations)\n",
        "    logger.info(\"=\"*50)\n",
        "\n",
        "    return \"spotify_basic_analysis.png\", observations\n"
      ],
      "metadata": {
        "id": "y8eY4l1QWSwk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}