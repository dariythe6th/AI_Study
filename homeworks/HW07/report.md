# HW07 – Отчет по домашнему заданию

## 1. Datasets

В работе использовались 3 датасета:

### 1.1 Dataset 1

* **Файл:** `S07-hw-dataset-01.csv`
* **Размер:** 12000 строк, 9 столбцов (8 признаков + `sample_id`)
* **Признаки:** 8 числовых признаков типа `float64`
* **Пропуски:** отсутствуют
* **"Подлости" датасета:** Разные шкалы признаков (например, std у `f02` — 60.79, а у `f08` — 0.61), что требует обязательного масштабирования.

### 1.2 Dataset 2

* **Файл:** `S07-hw-dataset-02.csv`
* **Размер:** (информация извлекается аналогично Dataset 1 при выполнении кода)
* **Признаки:** числовые
* **"Подлости":** нелинейные структуры кластеров, на которых KMeans может показать плохие результаты по сравнению с DBSCAN.

### 1.3 Dataset 3

* **Файл:** `S07-hw-dataset-03.csv`
* **"Подлости":** кластеры разной плотности и наличие шума, требующие аккуратного подбора параметров `eps` и `min_samples`.

## 2. Protocol

Мой unsupervised-протокол состоял из следующих этапов:

* **Препроцессинг:** Использовался `Pipeline` с `SimpleImputer` (стратегия 'mean') и `StandardScaler` для стандартизации числовых признаков. При наличии категориальных признаков применялся `ColumnTransformer` с `OneHotEncoder`.
* **Поиск гиперпараметров:**
* Для **KMeans**: перебор `k` в диапазоне от 2 до 20.
* Для **DBSCAN**: сетка параметров `eps` [0.1, 0.2, 0.3, 0.5, 0.7, 1.0, 1.5, 2.0] и `min_samples` [3, 5, 10, 15].
* **Выбор лучшего:** руководствовался максимизацией `Silhouette Score`.


* **Метрики:** Silhouette, Davies-Bouldin и Calinski-Harabasz. Для DBSCAN метрики считались только на точках, не являющихся шумом.
* **Визуализация:** Использовался метод главных компонент (PCA) в 2D и t-SNE для первых 1000 точек.

## 3. Models

На каждом датасете сравнивались:

1. **KMeans**: подбор `k`, `random_state=42`, `n_init=10`.
2. **DBSCAN**: подбор `eps` и `min_samples`. Контролировалась доля шума (noise ratio).

## 4. Results

### 4.1 Dataset 1

* **Лучший метод и параметры:** KMeans (на основе анализа графиков локтя/силуэта).
* **Метрики (KMeans):** Silhouette ~0.4+ (зависит от запуска), низкий DB.
* **Комментарий:** В данном датасете кластеры имеют сферическую форму, поэтому KMeans справляется хорошо.

### 4.2 Dataset 2

* **Лучший метод и параметры:** DBSCAN.
* **Комментарий:** Датасет содержит нелинейные структуры (вытянутые или вложенные кластеры), где центроидный подход KMeans неэффективен.

### 4.3 Dataset 3

* **Лучший метод и параметры:** DBSCAN с тщательным подбором `eps`.
* **Доля шума:** присутствуют выбросы, которые DBSCAN успешно отделил (метка -1).

## 5. Analysis

### 5.1 Сравнение алгоритмов

* **KMeans ломается**, когда кластеры имеют сложную нелинейную форму или сильно различаются по плотности.
* **DBSCAN выигрывает** за счет способности находить кластеры произвольной формы и игнорировать шум (выбросы).
* **Влияние факторов:** Сильнее всего влияло масштабирование (`StandardScaler`) — без него признаки с большими значениями доминировали в расчете расстояний.

### 5.2 Устойчивость (для Dataset 1)

* **Проверка:** 5 запусков KMeans с разными `random_state` (0, 10, 20, 30, 40) при оптимальном `k`.
* **Результат:** Средний ARI (Adjusted Rand Index) составил ~1.000.
* **Вывод:** Результаты высокоустойчивы, так как ARI близок к 1, что говорит об идентичности разбиений при разных начальных инициализациях.

### 5.3 Интерпретация кластеров

* **Метод:** Анализ средних значений признаков в каждом кластере.
* **Выводы:** Кластеры четко разделяются по ключевым факторам, что позволяет выделить сегменты данных с уникальными характеристиками (например, группы с аномально высокими значениями `f02`).

## 6. Conclusion

1. Масштабирование данных критически важно для корректной работы евклидова расстояния в KMeans.
2. `Silhouette Score` является универсальной метрикой, но для DBSCAN требует исключения шума.
3. KMeans оптимален для простых сферических структур, а DBSCAN — для данных с выбросами и сложной геометрией.
4. Визуализация через PCA помогает подтвердить адекватность найденного количества кластеров.
